min_power_cons : 1
max_power_cons : 300
sigma_1 : 0.5
sigma_2 : 0.5
epsilon : 0.000005 #convergence criteria
lr : [0.0001] # learning rate
max_iter : 10000 # maximum number of iterations
min_samples: 64 # minimum number of samples to represent alphabets - to update delta if the sample number is lower than this #qam_k :  k^2 QAM modulation
cons_type : 1 # 0:peak power, 1:average power, 2:first moment
n_snr : 10 # number of SNRs
nonlinearity : 3 # 0:linear, 1:nonlinear C1 (sgn(X)sqrt(abs(X))), 2: nonlinear C2 (sgn(X)abs(X)^{0.9}), 3:nonlinear tanh(X), 4:nonlinear x4: x/(1 + x^4)^1/4 # 5: nonlinear clip
clipping_limit_x : 2.5 # the limit in x for the clipping if nonlinear is clip  (x_c)
clipping_limit_y : 2.5 # the limit in y for the clipping if nonlinear is clip  (x_c)
output_dir : 'Res-PP-P' # file name to save the results
tanh_factor : 10 # k when the nonlinearity is tanh(x/k)
regime : 3 # 1: first regime phi(X)+N , 2: second regime phi(X+N), 3: third regime phi(X+Z_1)+Z_2
stop_sd : 4 # the length of the sigma, alphabet_x, pdf_x, powerl is taken as stop_sd*sigma extra while calculating the alphabet
gd_active : True # the gradient descent is active
gd_initial_ba : False # It has to be peak power constraint
bound_active: True
ba_active : False # Blahut Arimoto - only works with the peak power constraint
time_division_active: False # When this is active, I have only one SNR is active - forced in the code
n_time_division: 10
power_change_active: False # R1 and R2 boosts their power according to the time allocated to them to use the same power for the total duration
gd_nostop_cond : False  #epsilon is useless if it's true
complex : False # complex alphabet and pdf
x2_fixed : False

